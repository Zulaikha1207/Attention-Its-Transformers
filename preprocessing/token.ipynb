{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "token is any broken down part/word. A letter can be a token, a word can be a token\n",
    "character level embeddings/ tokens are advantageous because theres a limited no. of possible characters and so the langugae models get familiar. Word embeddings on the other hand are less easy to learn because there are ndless number of words/languages, etc. also words carry a level of semantic meaning in comparision to character. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "special tokens are place holders that represent distinctive things like names, urls, emails. ex: consider tweet: \"@elonmusk is a dumbasss\"\n",
    "in this tweet @elonmusk is not read as a name, its read as probably noise or just an extra token but with special tokens you can choose to give significance or highlight such words the tweet is rewritten as $<USER>$ is a dumbass. this is a special token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "special model tokens. \n",
    "BERT specific tokens:\n",
    "- [PAD] - padding token to maintain same length sequence for all tokens (this is important when feeding input to models such as RNNs or NNs in general)\n",
    "- [UNK] - unknown word \n",
    "- [CLS] - start of sequence\n",
    "- [SEP] - end of sequence and a seperator\n",
    "- [MASK] - place it when training BERT like models to guess a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '[UNK]',\n",
       " 'thinks',\n",
       " 'that',\n",
       " 'the',\n",
       " 'world',\n",
       " 'is',\n",
       " 'inside',\n",
       " 'a',\n",
       " '[UNK]',\n",
       " 'model',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example tweet: @elonmusk thinks that the world is inside a huggingface model\n",
    "\n",
    "\"[CLS] [UNK] thinks that the world is inside a [UNK] model [SEP] [PAD] [PAD]\".split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
